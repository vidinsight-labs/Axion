#!/usr/bin/env python3
"""
CPU-Bound Performance Benchmark Testi

Bu test, CPU-yoÄŸun gÃ¶revlerde paralel iÅŸleme verimliliÄŸini Ã¶lÃ§er.
"""

import sys
import time
import statistics
import multiprocessing
from pathlib import Path
from typing import List, Dict, Any, Optional
from dataclasses import dataclass, field

# Proje root'unu path'e ekle
sys.path.insert(0, str(Path(__file__).parent.parent))

from cpu_load_balancer import Engine, EngineConfig, Task, TaskType


@dataclass
class CPUBenchmarkResult:
    """CPU benchmark sonuÃ§larÄ±"""
    test_name: str
    num_tasks: int
    num_workers: int
    sequential_time: Optional[float] = None
    parallel_time: float = 0.0
    throughput: float = 0.0
    speedup_ratio: float = 0.0
    cpu_usage_avg: float = 0.0
    cpu_usage_max: float = 0.0
    latency_stats: Dict[str, float] = field(default_factory=dict)
    success_rate: float = 0.0


def run_sequential_baseline(script_path: str, params: Dict, num_iterations: int) -> float:
    """
    Sequential (tek thread) baseline Ã¶lÃ§Ã¼mÃ¼
    
    Args:
        script_path: Test script path
        params: Script parametreleri
        num_iterations: KaÃ§ kez Ã§alÄ±ÅŸtÄ±rÄ±lacak
    
    Returns:
        float: Toplam sÃ¼re (saniye)
    """
    import importlib.util
    
    # Script'i yÃ¼kle
    spec = importlib.util.spec_from_file_location("test_module", script_path)
    module = importlib.util.module_from_spec(spec)
    spec.loader.exec_module(module)
    
    # Mock context
    class MockContext:
        def __init__(self):
            self.task_id = "sequential-test"
            self.worker_id = "sequential"
    
    context = MockContext()
    
    # Sequential Ã§alÄ±ÅŸtÄ±r
    start_time = time.time()
    for _ in range(num_iterations):
        module.main(params, context)
    end_time = time.time()
    
    return end_time - start_time


def monitor_cpu_usage(duration: float, interval: float = 0.1) -> tuple:
    """
    CPU kullanÄ±mÄ±nÄ± izler
    
    Args:
        duration: Ä°zleme sÃ¼resi (saniye)
        interval: Ã–lÃ§Ã¼m aralÄ±ÄŸÄ± (saniye)
    
    Returns:
        tuple: (avg_cpu, max_cpu, samples)
    """
    try:
        import psutil
        cpu_samples = []
        start_time = time.time()
        
        while time.time() - start_time < duration:
            cpu_percent = psutil.cpu_percent(interval=interval)
            cpu_samples.append(cpu_percent)
            time.sleep(interval)
        
        if cpu_samples:
            return (
                statistics.mean(cpu_samples),
                max(cpu_samples),
                len(cpu_samples)
            )
    except ImportError:
        # psutil yoksa None dÃ¶ndÃ¼r
        return (0.0, 0.0, 0)
    
    return (0.0, 0.0, 0)


def run_cpu_bound_test(
    engine: Engine,
    script_path: str,
    test_name: str,
    task_params: Dict,
    num_tasks: int,
    num_workers: int,
    run_sequential: bool = True
) -> CPUBenchmarkResult:
    """
    CPU-bound test Ã§alÄ±ÅŸtÄ±rÄ±r
    
    Args:
        engine: Engine instance
        script_path: Test script path
        test_name: Test adÄ±
        task_params: Task parametreleri
        num_tasks: GÃ¶rev sayÄ±sÄ±
        num_workers: Worker sayÄ±sÄ±
        run_sequential: Sequential baseline Ã§alÄ±ÅŸtÄ±rÄ±lsÄ±n mÄ±
    
    Returns:
        CPUBenchmarkResult: Test sonuÃ§larÄ±
    """
    print(f"\n{'='*70}")
    print(f"ğŸ§ª Test: {test_name}")
    print(f"{'='*70}")
    print(f"   - GÃ¶rev sayÄ±sÄ±: {num_tasks}")
    print(f"   - Worker sayÄ±sÄ±: {num_workers}")
    print(f"   - Parametreler: {task_params}")
    
    # Sequential baseline (opsiyonel)
    sequential_time = None
    
    
    # Parallel test
    print(f"\nğŸ“¤ {num_tasks} gÃ¶rev gÃ¶nderiliyor...")
    
    task_ids = []
    start_time = time.time()
    
    # GÃ¶revleri gÃ¶nder
    for i in range(num_tasks):
        task = Task.create(
            script_path=script_path,
            params=task_params,
            task_type=TaskType.CPU_BOUND
        )
        task_id = engine.submit_task(task)
        task_ids.append(task_id)
    
    submit_time = time.time() - start_time
    print(f"   âœ… GÃ¶nderim tamamlandÄ± ({submit_time:.3f} saniye)")
    
    # GÃ¶revlerin worker'lara daÄŸÄ±lmasÄ± iÃ§in kÄ±sa bir bekleme
    print(f"   â³ GÃ¶revlerin worker'lara daÄŸÄ±lmasÄ± bekleniyor...")
    time.sleep(0.5)  # 500ms bekle - gÃ¶revlerin queue'lara ve worker'lara ulaÅŸmasÄ± iÃ§in
    
    # GÃ¶rev daÄŸÄ±lÄ±mÄ±nÄ± kontrol et
    print(f"\nğŸ“Š GÃ¶rev DaÄŸÄ±lÄ±mÄ± (GÃ¶nderim sonrasÄ±):")
    try:
        status = engine.get_status()
        
        # InputQueue durumu (gÃ¶revler burada bekliyor olabilir)
        if "input_queue" in status["components"]:
            input_queue_metrics = status["components"]["input_queue"]["metrics"]
            print(f"   Input Queue: {input_queue_metrics.get('size', 0)} gÃ¶rev bekliyor")
            print(f"      Toplam gÃ¶nderilen: {input_queue_metrics.get('total_put', 0)}")
            print(f"      DÃ¼ÅŸen gÃ¶revler: {input_queue_metrics.get('total_dropped', 0)}")
        
        pool_metrics = status["components"]["process_pool"]["metrics"]
        
        # Toplam aktif gÃ¶rev sayÄ±sÄ±
        total_active = pool_metrics.get("total_active_threads", 0)
        print(f"   Toplam Aktif GÃ¶rev: {total_active}")
        
        # CPU worker'larÄ±n durumu
        if "cpu_worker_tasks" in pool_metrics:
            print(f"   CPU Workers:")
            total_cpu_active = 0
            total_cpu_queue = 0
            for worker_id, worker_info in pool_metrics["cpu_worker_tasks"].items():
                active = worker_info['active_tasks']
                queue = worker_info['queue_size']
                total_cpu_active += active
                total_cpu_queue += queue
                print(f"      {worker_id}: {active} aktif gÃ¶rev, "
                      f"{queue} kuyrukta, "
                      f"{worker_info['total_load']} toplam yÃ¼k")
            print(f"      CPU Toplam: {total_cpu_active} aktif, {total_cpu_queue} kuyrukta")
        
        # IO worker'larÄ±n durumu
        if "io_worker_tasks" in pool_metrics:
            print(f"   IO Workers:")
            total_io_active = 0
            total_io_queue = 0
            for worker_id, worker_info in pool_metrics["io_worker_tasks"].items():
                active = worker_info['active_tasks']
                queue = worker_info['queue_size']
                total_io_active += active
                total_io_queue += queue
                print(f"      {worker_id}: {active} aktif gÃ¶rev, "
                      f"{queue} kuyrukta, "
                      f"{worker_info['total_load']} toplam yÃ¼k")
            print(f"      IO Toplam: {total_io_active} aktif, {total_io_queue} kuyrukta")
        
        # Ã–zet
        input_queue_size = status["components"].get("input_queue", {}).get("metrics", {}).get("size", 0)
        total_found = total_active + total_cpu_queue + total_io_queue + input_queue_size
        print(f"\n   ğŸ“ˆ Ã–zet: {num_tasks} gÃ¶rev gÃ¶nderildi")
        print(f"      InputQueue'da: {input_queue_size}")
        print(f"      Aktif: {total_active}")
        print(f"      Worker queue'larÄ±nda: {total_cpu_queue + total_io_queue}")
        print(f"      Toplam bulunan: {total_found}")
        if total_found < num_tasks:
            missing = num_tasks - total_found
            print(f"      âš ï¸  {missing} gÃ¶rev kayÄ±p gÃ¶rÃ¼nÃ¼yor!")
        
    except Exception as e:
        print(f"   âš ï¸  Worker durumu alÄ±namadÄ±: {e}")
        import traceback
        traceback.print_exc()
    
    # CPU monitoring baÅŸlat
    print(f"\nâ³ SonuÃ§lar bekleniyor ve CPU izleniyor...")
    
    # CPU Ã¶lÃ§Ã¼mÃ¼ iÃ§in psutil kullan
    cpu_samples = []
    try:
        import psutil
        cpu_monitoring = True
    except ImportError:
        cpu_monitoring = False
        print("   âš ï¸  psutil bulunamadÄ±, CPU metrikleri atlanacak")
    
    # SonuÃ§larÄ± al ve CPU izle
    results = []
    latencies = []
    
    # Worker monitoring iÃ§in
    last_status_time = time.time()
    status_interval = 1.0  # 1 saniye
    
    for i, task_id in enumerate(task_ids):
        # CPU Ã¶lÃ§Ã¼mÃ¼ (periyodik)
        if cpu_monitoring and i % max(1, num_tasks // 20) == 0:
            try:
                cpu_percent = psutil.cpu_percent(interval=0.01)
                cpu_samples.append(cpu_percent)
            except:
                pass
        
        # Worker durumunu saniyede bir yazdÄ±r
        current_time = time.time()
        if current_time - last_status_time >= status_interval:
            try:
                status = engine.get_status()
                pool_metrics = status["components"]["process_pool"]["metrics"]
                
                elapsed = current_time - start_time
                print(f"\n   ğŸ“Š Worker Durumu (t={elapsed:.1f}s):")
                
                # CPU worker'larÄ±n durumu
                if "cpu_worker_tasks" in pool_metrics:
                    for worker_id, worker_info in pool_metrics["cpu_worker_tasks"].items():
                        print(f"      {worker_id}: {worker_info['active_tasks']} aktif, "
                              f"{worker_info['queue_size']} kuyruk, "
                              f"{worker_info['total_load']} toplam")
                
                # IO worker'larÄ±n durumu
                if "io_worker_tasks" in pool_metrics:
                    for worker_id, worker_info in pool_metrics["io_worker_tasks"].items():
                        print(f"      {worker_id}: {worker_info['active_tasks']} aktif, "
                              f"{worker_info['queue_size']} kuyruk, "
                              f"{worker_info['total_load']} toplam")
                
                last_status_time = current_time
            except Exception as e:
                pass  # Hata durumunda sessizce devam et
        
        result = engine.get_result(task_id, timeout=60.0)
        if result:
            results.append(result)
            if result.duration:
                latencies.append(result.duration)
        
        if (i + 1) % max(1, num_tasks // 10) == 0:
            print(f"   âœ… {i + 1}/{num_tasks} sonuÃ§ alÄ±ndÄ±")
    
    parallel_time = time.time() - start_time
    
    # Final gÃ¶rev daÄŸÄ±lÄ±mÄ±nÄ± kontrol et
    print(f"\nğŸ“Š GÃ¶rev DaÄŸÄ±lÄ±mÄ± (Test sonrasÄ±):")
    try:
        status = engine.get_status()
        pool_metrics = status["components"]["process_pool"]["metrics"]
        
        # CPU worker'larÄ±n durumu
        if "cpu_worker_tasks" in pool_metrics:
            print(f"   CPU Workers:")
            for worker_id, worker_info in pool_metrics["cpu_worker_tasks"].items():
                print(f"      {worker_id}: {worker_info['active_tasks']} aktif gÃ¶rev, "
                      f"{worker_info['queue_size']} kuyrukta, "
                      f"{worker_info['total_load']} toplam yÃ¼k")
        
        # IO worker'larÄ±n durumu
        if "io_worker_tasks" in pool_metrics:
            print(f"   IO Workers:")
            for worker_id, worker_info in pool_metrics["io_worker_tasks"].items():
                print(f"      {worker_id}: {worker_info['active_tasks']} aktif gÃ¶rev, "
                      f"{worker_info['queue_size']} kuyrukta, "
                      f"{worker_info['total_load']} toplam yÃ¼k")
    except Exception as e:
        print(f"   âš ï¸  Worker durumu alÄ±namadÄ±: {e}")
    
    # Metrikleri hesapla
    successful = len([r for r in results if r.is_success])
    success_rate = successful / len(results) if results else 0.0
    throughput = len(results) / parallel_time if parallel_time > 0 else 0.0
    
    # Latency istatistikleri
    latency_stats = {}
    if latencies:
        latency_stats = {
            "avg": statistics.mean(latencies),
            "min": min(latencies),
            "max": max(latencies),
            "p50": statistics.median(latencies),
            "p95": sorted(latencies)[int(len(latencies) * 0.95)] if len(latencies) > 0 else 0,
            "p99": sorted(latencies)[int(len(latencies) * 0.99)] if len(latencies) > 0 else 0,
        }
    
    # Speedup ratio
    speedup_ratio = 0.0
    if sequential_time and sequential_time > 0:
        speedup_ratio = sequential_time / parallel_time
    
    # CPU kullanÄ±mÄ±
    if cpu_samples:
        avg_cpu = statistics.mean(cpu_samples)
        max_cpu = max(cpu_samples)
    else:
        avg_cpu = 0.0
        max_cpu = 0.0
    
    result = CPUBenchmarkResult(
        test_name=test_name,
        num_tasks=num_tasks,
        num_workers=num_workers,
        sequential_time=sequential_time,
        parallel_time=parallel_time,
        throughput=throughput,
        speedup_ratio=speedup_ratio,
        cpu_usage_avg=avg_cpu,
        cpu_usage_max=max_cpu,
        latency_stats=latency_stats,
        success_rate=success_rate
    )
    
    # SonuÃ§larÄ± yazdÄ±r
    print(f"\nğŸ“Š SonuÃ§lar:")
    print(f"   - Parallel sÃ¼re: {parallel_time:.3f} saniye")
    if sequential_time:
        print(f"   - Sequential sÃ¼re: {sequential_time:.3f} saniye")
        print(f"   - Speedup ratio: {speedup_ratio:.2f}x")
    print(f"   - Throughput: {throughput:.2f} gÃ¶rev/saniye")
    print(f"   - BaÅŸarÄ± oranÄ±: {success_rate*100:.1f}%")
    if avg_cpu > 0:
        print(f"   - Ortalama CPU: {avg_cpu:.1f}%")
        print(f"   - Maksimum CPU: {max_cpu:.1f}%")
    if latency_stats:
        print(f"   - Ortalama latency: {latency_stats['avg']*1000:.2f} ms")
        print(f"   - P95 latency: {latency_stats['p95']*1000:.2f} ms")
    
    return result


def run_fibonacci_benchmark(engine: Engine, script_path: str) -> List[CPUBenchmarkResult]:
    engine.shutdown()
    """Fibonacci benchmark testleri"""
    results = []
    
    # FarklÄ± worker sayÄ±larÄ± ile test
    cpu_count = multiprocessing.cpu_count()
    worker_configs = [1, 2, min(4, cpu_count), cpu_count]
    
    for num_workers in worker_configs:
        # Config gÃ¼ncelle
        
        
        # Shutdown sonrasÄ± bekle (process'lerin tamamen kapanmasÄ± iÃ§in)
        # Bu bekleme test sÃ¼resine dahil edilmez
        time.sleep(1.0)
        
        config = EngineConfig(
            cpu_bound_count=num_workers,
            io_bound_count=1,
            cpu_bound_task_limit=1,
            input_queue_size=1000,
            output_queue_size=5000
        )
        engine = Engine(config)
        engine.start()
        
        # Engine'in tamamen baÅŸlamasÄ±nÄ± bekle (test sÃ¼resine dahil deÄŸil)
        time.sleep(0.5)
        
        # Test parametreleri
        test_params = {"n": 35}  # Orta zorlukta
        
        result = run_cpu_bound_test(
            engine=engine,
            script_path=script_path,
            test_name=f"Fibonacci (n=35)",
            task_params=test_params,
            num_tasks=num_workers * 4,  # Worker baÅŸÄ±na 4 gÃ¶rev
            num_workers=num_workers,
            run_sequential=(num_workers == 1)  # Sadece ilk testte sequential
        )
        
        results.append(result)
        engine.shutdown()
    
    return results


def run_prime_benchmark(engine: Engine, script_path: str) -> List[CPUBenchmarkResult]:
    engine.shutdown()
    """Prime finding benchmark testleri"""
    results = []
    
    cpu_count = multiprocessing.cpu_count()
    worker_configs = [1, 2, min(4, cpu_count)]
    
    for num_workers in worker_configs:
        
        # Shutdown sonrasÄ± bekle (test sÃ¼resine dahil deÄŸil)
        time.sleep(1.0)
        
        config = EngineConfig(
            cpu_bound_count=num_workers,
            io_bound_count=1,
            cpu_bound_task_limit=1,
            input_queue_size=1000,
            output_queue_size=5000
        )
        engine = Engine(config)
        engine.start()
        
        # Engine'in tamamen baÅŸlamasÄ±nÄ± bekle (test sÃ¼resine dahil deÄŸil)
        time.sleep(0.5)
        
        test_params = {"start": 1000000, "count": 50}
        
        result = run_cpu_bound_test(
            engine=engine,
            script_path=script_path,
            test_name=f"Prime Finding (start=1M, count=50)",
            task_params=test_params,
            num_tasks=num_workers * 2,
            num_workers=num_workers,
            run_sequential=False
        )
        
        results.append(result)
        engine.shutdown()
    
    return results


def run_prime_chunk_benchmark(engine: Engine, script_path: str) -> List[CPUBenchmarkResult]:
    engine.shutdown()
    """Prime chunk benchmark testleri (range-based prime finding with extra CPU load)"""
    results = []
    
    cpu_count = multiprocessing.cpu_count()
    worker_configs = [1, 2, min(4, cpu_count)]
    
    # FarklÄ± zorluk seviyeleri
    test_configs = [
        {"start": 1_000_000, "range": 20_000, "extra_load": 300, "name": "Light"},
        {"start": 1_000_000, "range": 50_000, "extra_load": 500, "name": "Medium"},
        {"start": 2_000_000, "range": 30_000, "extra_load": 700, "name": "Heavy"},
    ]
    
    for num_workers in worker_configs:
        for test_config in test_configs:
            
            # Shutdown sonrasÄ± bekle (test sÃ¼resine dahil deÄŸil)
            time.sleep(1.0)
            
            config = EngineConfig(
                cpu_bound_count=num_workers,
                io_bound_count=1,
                cpu_bound_task_limit=1,
                input_queue_size=1000,
                output_queue_size=5000
            )
            engine = Engine(config)
            engine.start()
            
            # Engine'in tamamen baÅŸlamasÄ±nÄ± bekle (test sÃ¼resine dahil deÄŸil)
            time.sleep(0.5)
            
            test_params = {
                "start": test_config["start"],
                "range": test_config["range"],
                "extra_load": test_config["extra_load"]
            }
            
            result = run_cpu_bound_test(
                engine=engine,
                script_path=script_path,
                test_name=f"Prime Chunk ({test_config['name']}, start={test_config['start']//1_000_000}M, range={test_config['range']//1_000}K)",
                task_params=test_params,
                num_tasks=num_workers * 2,
                num_workers=num_workers,
                run_sequential=False
            )
            
            results.append(result)
            engine.shutdown()
    
    return results


def run_matrix_benchmark(engine: Engine, script_path: str) -> List[CPUBenchmarkResult]:
    engine.shutdown()
    """Matrix multiplication benchmark testleri"""
    results = []
    
    cpu_count = multiprocessing.cpu_count()
    worker_configs = [1, 2, min(4, cpu_count)]
    matrix_sizes = [100, 150, 200]
    
    for num_workers in worker_configs:
        for size in matrix_sizes:
            
            # Shutdown sonrasÄ± bekle (test sÃ¼resine dahil deÄŸil)
            time.sleep(1.0)
            
            config = EngineConfig(
                cpu_bound_count=num_workers,
                io_bound_count=1,
                cpu_bound_task_limit=1,
                input_queue_size=1000,
                output_queue_size=5000
            )
            engine = Engine(config)
            engine.start()
            
            # Engine'in tamamen baÅŸlamasÄ±nÄ± bekle (test sÃ¼resine dahil deÄŸil)
            time.sleep(0.5)
            
            test_params = {"size": size}
            
            result = run_cpu_bound_test(
                engine=engine,
                script_path=script_path,
                test_name=f"Matrix Multiplication ({size}x{size})",
                task_params=test_params,
                num_tasks=num_workers * 2,
                num_workers=num_workers,
                run_sequential=False
            )
            
            results.append(result)
            engine.shutdown()
    return results


def print_summary_table(results: List[CPUBenchmarkResult]):
    """SonuÃ§larÄ± tablo halinde yazdÄ±r"""
    print("\n" + "="*100)
    print("ğŸ“ˆ CPU-Bound Performance Benchmark Ã–zeti")
    print("="*100)
    
    print(f"{'Test':<30} {'Workers':<10} {'Time (s)':<12} {'Throughput':<15} {'Speedup':<10} {'CPU Avg':<10} {'Success':<10}")
    print("-"*100)
    
    for result in results:
        test_name = result.test_name[:28]
        workers = result.num_workers
        time_str = f"{result.parallel_time:.3f}"
        throughput = f"{result.throughput:.2f} task/s"
        speedup = f"{result.speedup_ratio:.2f}x" if result.speedup_ratio > 0 else "N/A"
        cpu_avg = f"{result.cpu_usage_avg:.1f}%" if result.cpu_usage_avg > 0 else "N/A"
        success = f"{result.success_rate*100:.1f}%"
        
        print(f"{test_name:<30} {workers:<10} {time_str:<12} {throughput:<15} {speedup:<10} {cpu_avg:<10} {success:<10}")


def main():
    """Ana fonksiyon"""
    print("="*70)
    print("ğŸš€ CPU Load Balancer - CPU-Bound Performance Benchmark")
    print("="*70)
    
    # Script path'leri
    base_dir = Path(__file__).parent
    fib_script = base_dir / "test_scripts" / "fibonacci_task.py"
    prime_script = base_dir / "test_scripts" / "prime_task.py"
    prime_chunk_script = base_dir / "test_scripts" / "prime_chunk.py"
    matrix_script = base_dir / "test_scripts" / "matrix_task.py"
    
    # Script'lerin varlÄ±ÄŸÄ±nÄ± kontrol et
    scripts = {
        "fibonacci": fib_script,
        "prime": prime_script,
        "prime_chunk": prime_chunk_script,
        "matrix": matrix_script
    }
    
    missing_scripts = []
    for name, path in scripts.items():
        if not path.exists():
            missing_scripts.append(str(path))
    
    if missing_scripts:
        print(f"\nâŒ Script'ler bulunamadÄ±:")
        for script in missing_scripts:
            print(f"   - {script}")
        print(f"\n   LÃ¼tfen Ã¶nce test script'lerini oluÅŸturun!")
        return 1
    
    all_results = []
    
    # Initial config
    config = EngineConfig(
        cpu_bound_count=3,
        io_bound_count=1,
        cpu_bound_task_limit=1,
        input_queue_size=1000,
        output_queue_size=5000
    )
    engine = Engine(config)
    engine.start()
    print(f"Engine status: {engine.get_status()}")
    
    try:
        # 1. Fibonacci Benchmark
        print("\n" + "="*70)
        print("1ï¸âƒ£  FIBONACCI BENCHMARK")
        print("="*70)
        fib_results = run_fibonacci_benchmark(engine, str(fib_script))
        all_results.extend(fib_results)
        
        # 2. Prime Finding Benchmark
        print("\n" + "="*70)
        print("2ï¸âƒ£  PRIME FINDING BENCHMARK")
        print("="*70)
        prime_results = run_prime_benchmark(engine, str(prime_script))
        all_results.extend(prime_results)
        
        # 3. Prime Chunk Benchmark
        print("\n" + "="*70)
        print("3ï¸âƒ£  PRIME CHUNK BENCHMARK")
        print("="*70)
        prime_chunk_results = run_prime_chunk_benchmark(engine, str(prime_chunk_script))
        all_results.extend(prime_chunk_results)
        
        # 4. Matrix Multiplication Benchmark
        print("\n" + "="*70)
        print("4ï¸âƒ£  MATRIX MULTIPLICATION BENCHMARK")
        print("="*70)
        matrix_results = run_matrix_benchmark(engine, str(matrix_script))
        all_results.extend(matrix_results)
        
        # Ã–zet tablo
        print_summary_table(all_results)
        
        # Analiz
        print("\n" + "="*70)
        print("ğŸ“Š Analiz")
        print("="*70)
        
        # Speedup analizi
        speedup_results = [r for r in all_results if r.speedup_ratio > 0]
        if speedup_results:
            avg_speedup = statistics.mean([r.speedup_ratio for r in speedup_results])
            max_speedup = max([r.speedup_ratio for r in speedup_results])
            print(f"   - Ortalama speedup: {avg_speedup:.2f}x")
            print(f"   - Maksimum speedup: {max_speedup:.2f}x")
        
        # CPU kullanÄ±m analizi
        cpu_usage_results = [r for r in all_results if r.cpu_usage_avg > 0]
        if cpu_usage_results:
            avg_cpu = statistics.mean([r.cpu_usage_avg for r in cpu_usage_results])
            max_cpu = max([r.cpu_usage_max for r in cpu_usage_results])
            print(f"   - Ortalama CPU kullanÄ±mÄ±: {avg_cpu:.1f}%")
            print(f"   - Maksimum CPU kullanÄ±mÄ±: {max_cpu:.1f}%")
        
        # Throughput analizi
        throughputs = [r.throughput for r in all_results if r.throughput > 0]
        if throughputs:
            print(f"   - Ortalama throughput: {statistics.mean(throughputs):.2f} gÃ¶rev/saniye")
            print(f"   - Maksimum throughput: {max(throughputs):.2f} gÃ¶rev/saniye")
        
    finally:
        engine.shutdown()
    
    return 0


if __name__ == "__main__":
    sys.exit(main())

